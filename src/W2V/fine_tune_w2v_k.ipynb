{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2f65a4-718f-4307-b590-06e6ce01ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "\n",
    "import more_itertools\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec49278-af9d-4a55-b466-a31b51b96f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map tokens to existings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667e9e4d-5425-4f9d-bf93-a37d2242f1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus\n",
      "Loaded corpus\n"
     ]
    }
   ],
   "source": [
    "# get existing tokens\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Loading corpus\")\n",
    "with open(\"data/processed.pkl\", \"rb\") as f:\n",
    "    (\n",
    "        corpus,\n",
    "        tokens,  # corpus as tokens\n",
    "        words_to_ids,\n",
    "        ids_to_words,\n",
    "    ) = pickle.load(f)\n",
    "print(\"Loaded corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c8c986-987b-4eaa-bf7d-f03281a07883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16680599"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756a91bb-632c-4558-bed7-5a4a41e4d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d000b901-7d6e-4147-8c05-3369de0bd2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine-tune corpus created:  ['a', 'p2p', 'orchestrator', 'darcs', '2']\n",
      "Created fine tune lookup tables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subsampling: 100%|██████████| 8188131/8188131 [00:17<00:00, 467869.63it/s]\n",
      "Sliding window: 100%|█████████▉| 5871651/5871655 [02:13<00:00, 43911.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# get fine-tune vocab\n",
    "with open(\"1m_titles.txt\") as f:\n",
    "    titles: str = f.read()\n",
    "\n",
    "# get fine-tune tokens \n",
    "def preprocess(text: str) -> list[str]:\n",
    "    text = text.lower()\n",
    "    text = text.replace(\".\", \" <PERIOD> \")\n",
    "    text = text.replace(\",\", \" <COMMA> \")\n",
    "    text = text.replace('\"', \" <QUOTATION_MARK> \")\n",
    "    text = text.replace(\";\", \" <SEMICOLON> \")\n",
    "    text = text.replace(\"!\", \" <EXCLAMATION_MARK> \")\n",
    "    text = text.replace(\"?\", \" <QUESTION_MARK> \")\n",
    "    text = text.replace(\"(\", \" <LEFT_PAREN> \")\n",
    "    text = text.replace(\")\", \" <RIGHT_PAREN> \")\n",
    "    text = text.replace(\"--\", \" <HYPHENS> \")\n",
    "    text = text.replace(\"?\", \" <QUESTION_MARK> \")\n",
    "    text = text.replace(\":\", \" <COLON> \")\n",
    "    words = text.split()\n",
    "    stats = collections.Counter(words)\n",
    "    words = [word for word in words if stats[word] > 5]\n",
    "    return words\n",
    "\n",
    "\n",
    "ft_corpus: list[str] = preprocess(titles)\n",
    "print(f\"fine-tune corpus created: \", ft_corpus[:5])\n",
    "\n",
    "def create_lookup_tables(words: list[str]) -> tuple[dict[str, int], dict[int, str]]:\n",
    "    word_counts = collections.Counter(words)\n",
    "    vocab = sorted(word_counts, key=lambda k: word_counts.get(k), reverse=True)\n",
    "    int_to_vocab = {ii + 1: word for ii, word in enumerate(vocab)}\n",
    "    int_to_vocab[0] = \"<PAD>\"\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "# Subsample corpus\n",
    "def subsample_corpus(corpus_tokens, threshold):\n",
    "    token_counts = collections.Counter(corpus_tokens)\n",
    "\n",
    "    def keep_probability(token) -> float:\n",
    "        return 1 - np.sqrt((total_token_len * threshold) / token_counts[token])\n",
    "\n",
    "    tqdm_tkn = tqdm(corpus_tokens, desc=\"Subsampling\")\n",
    "\n",
    "    subsampled = [\n",
    "        token for token in tqdm_tkn if keep_probability(token) > np.random.ranf()\n",
    "    ]\n",
    "    return subsampled\n",
    "\n",
    "\n",
    "ft_words_to_ids, ft_ids_to_words = create_lookup_tables(ft_corpus)\n",
    "print(\"Created fine tune lookup tables\")\n",
    "ft_tokens = [ft_words_to_ids[word] for word in ft_corpus]\n",
    "ft_token_counts = collections.Counter(ft_tokens)\n",
    "total_token_len = len(ft_tokens)\n",
    "\n",
    "ft_tokens_sub = subsample_corpus(corpus_tokens=ft_tokens, threshold=1e-5)\n",
    "\n",
    "context_window = 5\n",
    "if context_window % 2 == 0:\n",
    "    raise Exception(\n",
    "        f\"Context Window must be an odd number, currently: {context_window}\"\n",
    "    )\n",
    "center_i = context_window // 2\n",
    "\n",
    "windows = more_itertools.windowed(ft_tokens_sub, context_window)\n",
    "\n",
    "wind_tq = tqdm(windows, desc=\"Sliding window\", total=len(ft_tokens_sub))\n",
    "neg_sample_count = 20\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "neg_samples = []\n",
    "for tkn_wind in wind_tq:\n",
    "    inputs.append(tkn_wind[center_i])\n",
    "    targets.append(tkn_wind[:center_i] + tkn_wind[center_i + 1 :])\n",
    "    negs = [\n",
    "        words_to_ids[corpus[id]]\n",
    "        for id in np.random.randint(0, total_token_len, neg_sample_count)\n",
    "    ]\n",
    "    neg_samples.append(negs)\n",
    "\n",
    "\n",
    "input_tensor = torch.LongTensor(inputs)\n",
    "target_tensor = torch.LongTensor(targets)\n",
    "negs_tensor = torch.LongTensor(neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce288edb-8c7e-4bf3-9461-bcd5b57d599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_ids_to_words\n",
    "def map_fine_tune_tokens(ft_tokens, ids_to_words):\n",
    "    words_to_ids = {word: id_ for id_, word in ids_to_words.items()}\n",
    "    \n",
    "    ft_ids_to_words = {}\n",
    "\n",
    "    for token in ft_tokens:\n",
    "        ft_ids_to_words[token] = words_to_ids.get(token, 0)\n",
    "    \n",
    "    return ft_ids_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520f44a3-4f17-4da8-8938-5ab2f6bc3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_ids_to_words = map_fine_tune_tokens(ft_tokens, ids_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c9a1e6-0211-4c14-8459-aa9e03217506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45181"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ft_ids_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b5215-96f9-434d-b927-43caf9af05c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be17fc19-9042-48d9-9099-7f001a26dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.center_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_projection_embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # self.sig = nn.Sigmoid()\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def get_loss(self, inpt, trgs, rand):\n",
    "        emb = self.center_embed(inpt)\n",
    "\n",
    "        ctx = self.context_projection_embed(trgs)\n",
    "\n",
    "        neg = self.context_projection_embed(rand)\n",
    "\n",
    "        pos_logits = torch.bmm(ctx, emb.unsqueeze(-1)).squeeze()\n",
    "        neg_logits = torch.bmm(neg, emb.unsqueeze(-1)).squeeze()\n",
    "\n",
    "        pos_labels = torch.ones_like(pos_logits)\n",
    "        neg_labels = torch.zeros_like(neg_logits)\n",
    "\n",
    "        logits = torch.cat([pos_logits, neg_logits], dim=1)\n",
    "        labels = torch.cat([pos_labels, neg_labels], dim=1)\n",
    "\n",
    "        return self.loss(logits, labels)\n",
    "\n",
    "    def forward(self, id):\n",
    "        return self.center_embed(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6c66a9c-9781-4d91-b2af-bae69c35acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise model \n",
    "vocab_size = len(ids_to_words)\n",
    "embed_dim = 50\n",
    "model = Word2Vec(embed_dim, len(ids_to_words)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb448265-78ab-4f31-acbf-fd336498afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d79579-3d8a-4269-9f89-cd42064543d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2V loaded\n"
     ]
    }
   ],
   "source": [
    "# initialise model with saved weights and biases \n",
    "# Model setup\n",
    "# Load the w2v weights via the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "w2v = Word2Vec(embed_dim, vocab_size).to(device)\n",
    "model_path = \"models/w2v_epoch_11.pth\"\n",
    "\n",
    "w2v.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "print(\"W2V loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80ebccec-2647-4b8f-99e6-3a7439bcb2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialised\n",
      "Loaded dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Model initialised\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "context_window = 5\n",
    "batch_size = 500_000\n",
    "\n",
    "load_path = \"1m_titles_set.pth\"\n",
    "# input_tensor, target_tensor, negs_tensor = torch.load(load_path)\n",
    "dataset = torch.utils.data.TensorDataset(input_tensor, target_tensor, negs_tensor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(\"Loaded dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335ceaa-95dd-4643-a4c9-535194c175bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8396d2c0-57b2-4d9f-8c56-5675b07ad978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:d1qiwuj4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">recovering</strong> at: <a href='https://wandb.ai/kaleb-sofer-mlx/word2vec/runs/d1qiwuj4' target=\"_blank\">https://wandb.ai/kaleb-sofer-mlx/word2vec/runs/d1qiwuj4</a><br/> View project at: <a href='https://wandb.ai/kaleb-sofer-mlx/word2vec' target=\"_blank\">https://wandb.ai/kaleb-sofer-mlx/word2vec</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241018_135103-d1qiwuj4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:d1qiwuj4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20241018_135809-48wu0rhs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kaleb-sofer-mlx/word2vec/runs/48wu0rhs' target=\"_blank\">recovering</a></strong> to <a href='https://wandb.ai/kaleb-sofer-mlx/word2vec' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kaleb-sofer-mlx/word2vec' target=\"_blank\">https://wandb.ai/kaleb-sofer-mlx/word2vec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kaleb-sofer-mlx/word2vec/runs/48wu0rhs' target=\"_blank\">https://wandb.ai/kaleb-sofer-mlx/word2vec/runs/48wu0rhs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 12/12 [01:27<00:00,  7.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▇▆▅▅▄▃▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>2.36106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">recovering</strong> at: <a href='https://wandb.ai/kaleb-sofer-mlx/word2vec/runs/48wu0rhs' target=\"_blank\">https://wandb.ai/kaleb-sofer-mlx/word2vec/runs/48wu0rhs</a><br/> View project at: <a href='https://wandb.ai/kaleb-sofer-mlx/word2vec' target=\"_blank\">https://wandb.ai/kaleb-sofer-mlx/word2vec</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241018_135809-48wu0rhs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"word2vec\",\n",
    "    name=\"recovering\",\n",
    "    config={\n",
    "        \"batch_size\": batch_size,\n",
    "        \"context_window\": context_window,\n",
    "        \"embed_dims\": embed_dim,\n",
    "    },\n",
    ")\n",
    "for epoch in range(1):\n",
    "    prgs = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for inputs, targets, negs in prgs:\n",
    "        inputs, targets, negs = inputs.to(device), targets.to(device), negs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = model.get_loss(inputs, targets, negs)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        wandb.log({\"loss\": loss.item()})\n",
    "\n",
    "    if (not (epoch + 1) % 5):\n",
    "        save_path = f\"checkpoints/w2v_epoch_{epoch+1}.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63cb50-f476-4b92-ab37-1f11da90db98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79423ea6-c649-48fb-b03f-6d0a3656fb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181f4ad-df47-48ed-8fc3-ef738a409b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f7187-2681-4651-9eb5-36c7faa5c83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ceb1e-5e68-41f3-ba46-6e4876e00ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ea8c7-22ab-4f26-b9f4-b4d8d8dc2e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e922752-82bf-4e02-b675-ca1fe3d8ae94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c6304-6d2a-4408-8226-a708b0b7689a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
